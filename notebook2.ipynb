{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e759c1e",
   "metadata": {},
   "source": [
    "### 4.10.1 Démarrage de la session Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f0fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'exécution de cette cellule démarre l'application Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aba202f",
   "metadata": {},
   "source": [
    "<u>Affichage des informations sur la session en cours et liens vers Spark UI</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb788991",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ac9832",
   "metadata": {},
   "source": [
    "### 4.10.2 Installation des packages\n",
    "\n",
    "Les packages nécessaires ont été installé via l'étape de **bootstrap** à l'instanciation du serveur.\n",
    "\n",
    "### 4.10.3 Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad562eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from keras.utils import img_to_array\n",
    "from keras.models import Model\n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83663cbd",
   "metadata": {},
   "source": [
    "### 4.10.4 Définition des PATH pour charger les images et enregistrer les résultats\n",
    "\n",
    "Nous accédons directement à nos **données sur S3** comme si elles étaient **stockées localement**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46be859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des chemins\n",
    "PATH = 's3://p8-lucile-data/'\n",
    "PATH_Data = PATH + '/Test'\n",
    "PATH_Result = PATH + '/Results'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf883c20",
   "metadata": {},
   "source": [
    "### 4.10.5 Traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffe93f5",
   "metadata": {},
   "source": [
    "#### 4.10.5.1 Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4b319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = spark.read.format('binaryFile') \\\n",
    "  .option('pathGlobFilter', '*.jpg') \\\n",
    "  .option('recursiveFileLookup', 'true') \\\n",
    "  .load(PATH_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bfeb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b32ac34",
   "metadata": {},
   "source": [
    "<u>Je ne conserve que le **path** de l'image et j'ajoute <br />\n",
    "    une colonne contenant les **labels** de chaque image</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ab808",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\n",
    "print(images.printSchema())\n",
    "print(images.select('path','label').show(5,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15b199",
   "metadata": {},
   "source": [
    "#### 4.10.5.2 Préparation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c7165",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNetV2(\n",
    "    weights = 'imagenet',\n",
    "    include_top = True,\n",
    "    input_shape = (224, 224, 3)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9bc650",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model(\n",
    "    inputs = model.input,\n",
    "    outputs = model.layers[-2].output\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d497f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "brodcast_weights = sc.broadcast(new_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8fe2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Returns a MobileNetV2 model with top layer removed \n",
    "    and broadcasted pretrained weights.\n",
    "    \"\"\"\n",
    "\n",
    "    model = MobileNetV2(\n",
    "        weights = 'imagenet',\n",
    "        include_top = True,\n",
    "        input_shape = (224, 224, 3)\n",
    "        )\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    new_model = Model(\n",
    "        inputs = model.input,\n",
    "        outputs = model.layers[-2].output\n",
    "        )\n",
    "    new_model.set_weights(brodcast_weights.value)\n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032f135",
   "metadata": {},
   "source": [
    "#### 4.10.5.3 Définition du processus de chargement des images <br/> et application de leur featurisation à travers l'utilisation de pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933100cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess(content):\n",
    "    \"\"\"\n",
    "    Preprocesses raw image bytes for prediction.\n",
    "    \"\"\"\n",
    "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
    "    arr = img_to_array(img)\n",
    "    return preprocess_input(arr)\n",
    "\n",
    "def featurize_series(model, content_series):\n",
    "    \"\"\"\n",
    "    Featurize a pd.Series of raw images using the input model.\n",
    "    :return: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    input = np.stack(content_series.map(preprocess))\n",
    "    preds = model.predict(input)\n",
    "    # For some layers, output features will be multi-dimensional tensors.\n",
    "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)\n",
    "\n",
    "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
    "def featurize_udf(content_series_iter):\n",
    "    '''\n",
    "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
    "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
    "\n",
    "    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n",
    "                              is a pandas Series of image data.\n",
    "    '''\n",
    "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
    "    # for multiple data batches.  This amortizes the overhead of loading big models.\n",
    "    model = model_fn()\n",
    "    for content_series in content_series_iter:\n",
    "        yield featurize_series(model, content_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23206e8",
   "metadata": {},
   "source": [
    "#### 4.10.5.4 Exécutions des actions d'extractions de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d760c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = images.repartition(24).select(\n",
    "    col('path'),\n",
    "    col('label'),\n",
    "    featurize_udf('content').alias('features')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7ee6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion des caractéristiques en vecteurs\n",
    "to_vector_udf = udf(lambda features: Vectors.dense(features), VectorUDT())\n",
    "features_vector_df = features_df.withColumn('features_vector', to_vector_udf('features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détermination du k optimal\n",
    "variance_df = []\n",
    "for k in range(1, 101):\n",
    "    pca = PCA(k=k, inputCol='features_vector', outputCol='pca_features')\n",
    "    model = pca.fit(features_vector_df)\n",
    "    explained_variance = model.explainedVariance.sum()\n",
    "    variance_df.append((k, explained_variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d2442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir en DataFrame pour trouver le k optimal\n",
    "variance_spark_df = spark.createDataFrame(variance_df, ['k', 'explained_variance'])\n",
    "optimal_k = variance_spark_df.orderBy(variance_spark_df.explained_variance.desc()).first()[0]\n",
    "\n",
    "print(f'Optimal number of components: {optimal_k}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bec9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer l'ACP avec le k optimal\n",
    "pca = PCA(k=optimal_k, inputCol='features_vector', outputCol='pca_features')\n",
    "pca_model = pca.fit(features_vector_df)\n",
    "pca_result_df = pca_model.transform(features_vector_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a930b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes nécessaires\n",
    "result_df = pca_result_df.select('path', 'label', 'pca_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8ca76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrement des résultats réduits\n",
    "result_df.write.mode('overwrite').parquet(PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe01b72",
   "metadata": {},
   "source": [
    "### 4.10.6 Chargement des données enregistrées et validation du résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db18a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(PATH_Result, engine = 'pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d750d2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29205ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0,'features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fba6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "432.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
